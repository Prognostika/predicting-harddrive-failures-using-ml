{
 "cells" : [
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "Predicting Hard Drive Failures Using SMART Metrics\n",
    "-----\n",
    "\n",
    "### <img src=\"images/JUUL_Logo_2018.jpg\" align=\"left\" height=\"40\" width=\"60\"> <br> - A Juul Labs Case Study \n"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "### What are SMART systems ?\n",
    "SMART features or *S.M.A.R.T. (Self-Monitoring, Analysis and Reporting Technology)* is a software monitoring system for hard drives. It is a widely used industry practice around data center management and disk heavy resources. SMART generates a collection different metrics related to help evaluate the overall health of a Hard Drive. These metrics can be specific to a certain number of manufacturers or be more general, sometimes. \n",
    "\n",
    "A single metrics may not always determine the exact failure prediction but are commonly accepted to help identify any imminent failure and help handle the backup and restore, in time. \n",
    "\n",
    "\n",
    "### About this case study :\n",
    "This case study relies on a given data stream provided for this purpose. The goal of this case study is to try and analyze given data and find out meaningful information that can help determine drives failure trends and different factors that may idicate if a drive would fail, and attempt to propose a more data driven answer to future failures based on SMART metrics.\n",
    "\n",
    "The study concludes with discussing possible opportunities and challenges with existing model and features that can help design a better predictive model for future. \n",
    "\n",
    "\n",
    "--------\n",
    "\n",
    "Here's a quick look of how this problem has been approached: \n",
    "\n",
    "### Extraction and Load\n",
    "1. Connect to the postgres server.\n",
    "2. Download the dataset offline\n",
    "\n",
    "### Transform\n",
    "3. Wrangle and explore\n",
    "4. Change Dimentions, clean and slice and dice\n",
    "\n",
    "### Analyze\n",
    "5. Analyze dataset, plot most significant trends\n",
    "\n",
    "### Predict:\n",
    "6. Feature Selection\n",
    "7. Model and predict\n",
    "\n",
    "### Conclusion and Improvement Ideas:\n",
    "8. Conclude\n",
    "9. Challenges with the current dataset and ways to improve it"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "-----------\n",
    "## Extraction and Load \n",
    "\n",
    "1. Connect to the postgres server\n",
    "-----------------\n",
    "* I'll begin by importing libraries to connect to postgres and download the dataset offline. \n",
    "* I will create a few database utility funtion get the table data and columns\n",
    "* next up, I will use pandas to join columns and dataset and transform incoming data into a pandas dataframe. \n",
    "* Lastly I will save the data locally in a csv format.\n",
    "\n",
    "\n",
    "Next up, I will beging wrangling and exploring the data to understand different attributes that will be used later on in analysis."
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn import ensemble, metrics"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "#### postgres database utility functions\n",
    "####\n",
    "\n",
    "# db connection object generator\n",
    "def postgres_db_connection(): \n",
    "    # postgresql://35.230.114.237\", \"postgres\", \"luuj\"\n",
    "    conn = psycopg2.connect(host=\"35.230.114.237\", dbname=\"postgres\", \n",
    "    user=\"candidate\", password=\"luuj\")\n",
    "    print('Connecting to postgresql server...')\n",
    "    cur = conn.cursor()\n",
    "    print('Successfully connected to the host\\n')\n",
    "    return cur\n",
    "\n",
    "\n",
    "def get_all_tables(cur):\n",
    "\tprint('Extracting list of tables:')\n",
    "\tcur.execute(\"SELECT * FROM pg_catalog.pg_tables where schemaname NOT IN ('pg_catalog', 'information_schema')\")\n",
    "\ttables = cur.fetchall()\n",
    "\tt = [i[1] for i in tables]\n",
    "\treturn t\n",
    "\n",
    "\n",
    "def lookup_a_table(cur, tablename):\n",
    "\t# get data from a given table: tablename\n",
    "\tprint(\"\\nReading table: \"+tablename+\"...\")\n",
    "    # cur.execute('SELECT * from '+tablename+' limit 10')\n",
    "\n",
    "\t# get table_data\n",
    "\tcur.execute(\"SELECT * from \"+tablename+' limit 10')\n",
    "\ttable_data = cur.fetchall()\n",
    "\treturn table_data\n",
    "\n",
    "\n",
    "def get_table_columns(cur, tablename):\n",
    "\n",
    "\t# get column_names\n",
    "\tprint('Fetching columns in: ', tablename)\n",
    "\ttry: \n",
    "\t\tcur.execute(\"SELECT table_name, column_name from information_schema.columns where table_name = '\"+tablename+\"'\")\n",
    "\t\tcolumn_names = cur.fetchall()\n",
    "\t\tcolumn_names = [j[1] for j in column_names]\n",
    "\texcept:\n",
    "\t\tprint('Column fetch failed')\n",
    "\n",
    "\treturn column_names\n",
    "\n",
    "\n",
    "# transform data in pandas and save table locally for offline analysis\n",
    "def clean_response(table, data, column_names):\n",
    "\t# inp: table data and column_names\n",
    "\t# out: pandas dataframe\n",
    "\n",
    "\tdata = pd.DataFrame(data)\n",
    "\tdata.columns = [column_names]\n",
    "\tout_file = 'out_data_from_tablename_'+table+'.csv'\n",
    "\tprint('Saving data from table: {}, to file: {}'.format(table, out_file))\n",
    "# \tdata.to_csv(out_file, index=False, encoding='utf-8')\n",
    "    \n",
    "\n",
    "# Etracting all tables at the host in a list and finally,\n",
    "# extracting the table we want i.e. 'hard_drive_stats\n",
    "db_conn_obj = postgres_db_connection()\n",
    "tables = get_all_tables(db_conn_obj)\n",
    "\n",
    "table = 'hard_drive_stats'\n",
    "data = lookup_a_table(db_conn_obj, table)\n",
    "table_data = lookup_a_table(db_conn_obj, table)\n",
    "table_column_names = get_table_columns(db_conn_obj, table)\n",
    "\n",
    "# transform data in pandas\n",
    "clean_response(table, table_data, table_column_names)"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "1. At the end of the above `code` snippet, data is downloaded and saved locally to current directory. \n",
    "2. Name: out_data_from_tablename_hard_drive_stats.csv"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "-------\n",
    "## Transform"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "1. Now, the dataset is downloaded. \n",
    "2. Filename is: out_data_from_tablename_hard_drive_stats.csv\n",
    "3. We shall be be using this file going forward, in order to avoid calling the postgres again and again."
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# loading dataset from local machine\n",
    "df = pd.read_csv('out_data_from_tablename_hard_drive_stats.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "#### Get basic look of the dataset"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# number of rows\n",
    "rows = df.shape[0]\n",
    "columns = df.shape[1]\n",
    "\n",
    "print('Number of rows are: {} and number of columns: {}\\n'.format(rows, columns))\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "#### More wrangling of  the data"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "First up, I get rid of some irrelevant columns and then indentify the top 10 hard drives.\n",
    "\n",
    "I will apply some cleaning on the columns, changing dtypes and more. Next, I discard/drop columns based on:\n",
    "1. high number of Nan\n",
    "2. irrelevance\n",
    "3. top 10 models"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# drop everything where 10 or more rows are Nan\n",
    "df = df.dropna(thresh=10, axis=0)\n",
    "\n",
    "\n",
    "# drop column row.names\n",
    "df = df.drop(['row.names'], axis=1)\n",
    "\n",
    "\n",
    "# change data type\n",
    "new_date = pd.to_datetime(df['date'])\n",
    "df['date'] = new_date"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "Data types now look like this:"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "df.shape"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "### Top 10 most common hard drives\n",
    "* After getting rid of some of the duplicates.\n",
    "* Now based the dataset, I am making the following assumptions:\n",
    "  1. Hard drives with number of datapoints are the most common hard drives.\n",
    "  2. Since there are multiple serial_numbers that belong to the same Hard Drive model, I am taking a unique count only."
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# getting a list of the msot common drives\n",
    "most_common_models = df.groupby(['model'], as_index=True)['model', 'date']. size()\n",
    "most_common_models = most_common_models.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "Most Common Models in descending order are:"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# number of different models \n",
    "print(\"There are 53 models: \", len(most_common_models))"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "#### Top 10 Models based on most number of Hard Drives are"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "scrolled" : false,
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "top10_models = most_common_models[:10]\n",
    "top10_models"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "top10_models.plot(kind='bar', legend= False)\n",
    "print('Top 10 common models and the number of hard Drives in each:')"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "### Filtering - Limiting the dataset by only top 10 models"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# top 10 models\n",
    "list_top10_models = [i for i in top10_models.index]\n",
    "\n",
    "# this is the new dataframe based on the top 10 models\n",
    "new_df = df[df['model'].isin(list_top10_models)]\n",
    "\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "---------\n",
    "#### Using the new dataframe from here on"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# Changing datatypes\n",
    "new_df['failure'] = new_df['failure'].astype('bool')\n",
    "\n",
    "# saving top10 models data to csv\n",
    "# new_df.to_csv('top10_models.csv', index=False)"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "-----\n",
    "## Analysis\n",
    "\n",
    "Keeping in mind that the resources available *do not* accurately describe this particular dataset. It is crucial to proceed with caution.\n",
    "\n",
    "I researched online and read a number of articles. I settled one the ones I found most relevant. I have used this information to help me understand the schema and it's various attributes. \n",
    "\n",
    "### Resources: \n",
    "These are some of the resources I found helpful. \n",
    "\n",
    "1. Understanding differet SMART stats: https://www.backblaze.com/blog/what-smart-stats-indicate-hard-drive-failures/ \n",
    "2. SMART schema on WIKI: https://en.wikipedia.org/wiki/S.M.A.R.T.#ATA_S.M.A.R.T._attributes \n",
    "3. Research Paper: http://cs229.stanford.edu/proj2017/final-reports/5242080.pdf\n",
    "\n",
    "\n",
    "### Tools: \n",
    "1. I have utilized scikit library for prediction.\n",
    "2. Partly used pandas and Google Big Query for faster analysis in SQL, and \n",
    "3. matplotlib + Google Data Studio for plotting charts. "
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "#### Let's check the cardinality of each columns"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# find unique values per columns\n",
    "for cols in new_df.columns:\n",
    "    print(\"{} has: {} unique values\".format(cols, len(new_df[cols].unique())))"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "### Plotting graphs to get a visual look and analyze\n",
    "-------\n",
    "#### Using Google Data Studio and Big Query:\n",
    "\n",
    "* Google Data Studio provides for a much more robust and interactive reporting system. \n",
    "* I loaded the dataset into Big Query and used Google Data Studio because of it's SQL support, interactive platform and robustness with doing exploratory analysis on a large dataset. \n",
    "* There are some key charts provided below. \n",
    "\n",
    "#### Click Here for a full report: https://datastudio.google.com/open/1vzmbcHsLQ-OMZZsfXUnECJbIteK_kdF7"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "#### Looking at the trends displayed below, we can derive the following (refer to the Studio Report below) :\n",
    "     \n",
    "1. Number of positive Hard drives failure trend are going down. This trend is proportional to the power cycle of the hard drives. This means that as the hard drives get old over time, they are more likely to fail. This is also verified by external sources, a typical life of a hard drive is around 5 years. This can help find out the likelyhood of a drive failing. \n",
    "\n",
    "\n",
    "2. Reported uncorrectable errors tend to go down as the failure count goes down over time. On the other hand, the reallocated sectors a going up. Both of these features should ideally be of a lower value for a healthy hard drive. There are higher chances of failure if both of these factors go up in the future.\n",
    "\n",
    "\n",
    "3. Hard Drives have to reallocated sectors at a much higher rate in the event of a failure. This happens becase hard drives need to remap the data to a different sector in order to avoid data loss. Frequent remapping like this is not a good sign of a healthy hard drive.\n",
    "\n",
    "4. High fly rates decrease with decrease in failure. This may indicate that a lower high fly rate is a potential sign of healthier hard drives.\n",
    "\n",
    "There are more exploratory analysis performed on google data studio report, link is provided below. "
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# rendering google data studio report\n",
    "from IPython.display import IFrame\n",
    "IFrame('https://datastudio.google.com/embed/reporting/1vzmbcHsLQ-OMZZsfXUnECJbIteK_kdF7/page/xJMf', width=900, height=675)"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "#### Assumptions made and references drawn, in performing the analysis: \n",
    "--------\n",
    "\n",
    "Since there isn't enough detail about the dataset in this case study, some external researching is required to get an understanding. \n",
    "\n",
    "\n",
    "There are exponetial values in some of SMART metrics. The provided data stream is raw and there isn't much information available online about different expoential values. I couldn't find a meaningful method to normalize the raw data to a 100 point scale in order to make a better correlation. \n",
    "\n",
    "#### Analysis Conclusion\n",
    "--------------\n",
    "\n",
    "In conclusion, the metrics in SMART systems are most often high uncorrelated. It wouldn't be recommended to rely on one of them to make a decision about a possible drive failure."
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "#### (This is Optional)\n",
    "*In case the above embeded code for Data Studio report failed, I am including local PNG import of some of the charts.*\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td> 1. Number Hard Drives per model\n",
    "<img src=\"graphs/hard-drives-per-model.png\" width=\"600\"> </td>\n",
    "    <td>2. Number of positive failures by model\n",
    "        <img src=\"graphs/failures-by-model.png\" width=\"600\"> </td></tr></table>\n",
    "        \n",
    "        \n",
    "<table>\n",
    "    <tr>\n",
    "        <td>3. Failure Trend over time\n",
    "            <img src=\"graphs/failure-trend-timeseries.png\" width=\"600\"></td>\n",
    "<td>4. Daily Failure Trend to determine missing failure data pattern\n",
    "    <img src=\"graphs/daily-trend-of-fails.png\" width=\"600\"></td></tr></table>"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : {
    "collapsed" : true
   },
   "source" : [
    "------\n",
    "## Machine learning to Predict Possible Failures based"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "### Feature selection:\n",
    "\n",
    "Based on my findings and research on SMART attributes, I have found the following variables to be the most significant out of the total available dataset. The variables are highly non correlated, I made the selection based on what works as a industry standard for SMART predictions."
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# get all columns and the number of NaN in them\n",
    "new_df.isna().sum()"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# new_df.groupby(['model'], as_index=True)['failure'].head()\n",
    "# failure_by_model = new_df.groupby('failure').agg('model').head()\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# featured selection\n",
    "# -----------------\n",
    "\n",
    "# selecting dataframe slice with no nan values.\n",
    "# first doing a row wise check to see if dropping rows will solve this\n",
    "featured_df = new_df.dropna(axis=0, how='any', thresh=15)\n",
    "featured_df.isna().sum()\n",
    "\n",
    "# there are still three metrics with very high number of nan\n",
    "# dropping more columns\n",
    "featured_df = featured_df.drop(['throughput_performance', 'seek_time_performance', 'high_fly_writes'], axis=1)\n",
    "\n",
    "# final dataframe is ready for any predictive usage\n",
    "# verify nan in featured_df\n",
    "featured_df.isna().sum()"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# quick look at the featured_df\n",
    "featured_df.shape\n",
    "\n",
    "# find unique models per columns\n",
    "len(featured_df['model'].unique())"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# number of dates in featured_df\n",
    "len(featured_df['date'].unique())"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# number of dates in featured_df\n",
    "len(featured_df['serial_number'].unique())"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# saving feature_df to csv, this is optional. \n",
    "# ----------------\n",
    "# using this to ocassionally push data to Big Query\n",
    "\n",
    "# this is optional for re-runs\n",
    "# featured_df.to_csv('featured_hard_drive_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn import ensemble, metrics"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# load featured hard drive dataset\n",
    "hdd = pd.read_csv('featured_hard_drive_dataset.csv')"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "hdd.shape"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# number of unique hard drives\n",
    "hdd['serial_number'].value_counts().shape\n",
    "\n",
    "# since hard drives serial number is unique across, we use this as the index"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# there are 6 models now left in the featured dataset\n",
    "hdd['model'].value_counts().shape"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "I've used Big Query in parts where I found it easy to do analysis using SQL. Below is the sql script to get % of failure per model\n",
    "#### SQL to get % of failure per model:\n",
    "```\n",
    "SELECT\n",
    "  model,\n",
    "  COUNT(DISTINCT serial_number) number_of_hdd,\n",
    "  SUM(IF(failure IS TRUE,\n",
    "      1,\n",
    "      0)) fails,\n",
    "  ROUND(SUM(IF(failure IS TRUE,\n",
    "        1,\n",
    "        0))/COUNT(DISTINCT serial_number),3) percentage_of_fails\n",
    "FROM\n",
    "\n",
    "  `orbital-linker-226700.pandey.hard_drive_stats_top10_models`\n",
    "GROUP BY\n",
    "  model order by number_of_hdd desc\n",
    "```"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# exported sql output and reading in pandas\n",
    "sql_output = pd.read_csv('reports/failure_percentage_by_model.csv')\n",
    "sql_output.head(10)\n",
    "\n",
    "# This shows that the data is highly imbalanced and the model with most fails is only about .006 or .06% of total data."
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "Above: Full list of model their % of failure"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [ ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# using ST4000DM000\t model\n",
    "hdd_st4000 = hdd.query('model == \"ST4000DM000\"')\n",
    "hdd_st4000.shape\n",
    "\n",
    "hdd_st4000['serial_number'].value_counts().shape\n",
    "\n",
    "# number of failures in this hard drive model\n",
    "hdd_st4000['failure'].value_counts()"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "### Preparing training and testing datasets using dataframe 'hdd'"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# using data from all models\n",
    "# -----------------\n",
    "date = pd.to_datetime(hdd['date'])\n",
    "hdd['date'] = date\n",
    "\n",
    "# add day of year using date column\n",
    "hdd['day_of_year'] = hdd['date'].dt.dayofyear\n",
    "\n",
    "# grouping by getting all unique hard drives\n",
    "# indexing by serial number as every hard drive will have a unique serial number\n",
    "\n",
    "hdd_group = hdd.groupby('serial_number')\n",
    "\n",
    "# take the last row from each group\n",
    "hdd_last_day = hdd_group.nth(-1)\n",
    "\n",
    "\n",
    "len(hdd_last_day['date'].unique())"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# total failure per model for one day\n",
    "hdd_last_day['failure'].value_counts()\n",
    "\n",
    "# number of drives in the dataset\n",
    "uniq_serial_numbers = pd.Series(hdd_last_day.index.unique())\n",
    "uniq_serial_numbers.shape"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "hdd_last_day['failure'].value_counts()"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# slicing a copy of 25% of all unique hard drives for test\n",
    "test_ids = uniq_serial_numbers.sample(frac=0.25)\n",
    "train = hdd_last_day.query('index not in @test_ids')\n",
    "test = hdd_last_day.query('index in @test_ids')\n",
    "\n",
    "# test data has now looks like this\n",
    "test.shape"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# test data\n",
    "test['failure'].value_counts()"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "train.shape"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# train data has remaining 24029 data points\n",
    "train['failure'].value_counts()"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# training and testing labels\n",
    "train_labels = train['failure']\n",
    "# failure is the final label we would like to predict \n",
    "test_labels = test['failure']\n",
    "\n",
    "# drop labels from train and test\n",
    "train = train.drop('failure', axis=1)\n",
    "test = test.drop('failure', axis=1)"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "train.shape"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "#drop date related features from tree model\n",
    "train = train.drop(['day_of_year', 'date'], axis=1)\n",
    "test = test.drop(['day_of_year', 'date'] , axis=1)\n",
    "\n",
    "# removing other irrelevant or constant columns\n",
    "\n",
    "# this is out final training and test dataset with all the right features\n",
    "train = train.drop(['model', 'capacity_bytes', 'power_on_hours', 'total_lbas_written'], axis=1)\n",
    "test = test.drop(['model', 'capacity_bytes', 'power_on_hours', 'total_lbas_written'], axis=1)"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "train.shape"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# these are the training features\n",
    "train.columns"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# check first 10 training labels\n",
    "train_labels[:10]"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "### Prediction using Random Forest Ensemble\n",
    "For prediction, I tried a couple of options from logistic regression to Naive Bayes but finally settled on random forest classifier tree for following reasons:\n",
    "1. Data is full of poorly correlated SMART features.\n",
    "3. For regression, normalization of some of the attributes would be required. \n",
    "4. Since there isn't much information available on how different large float values can be normalized, it's a better idea to stick with the absolute numbers only\n",
    "5. Use raw values instead of normalization since normalization has no impact on performance of a tree.\n",
    "6. Random forest classifiers are designed to reduce the overall error rate and work over raw data.\n",
    "\n",
    "#### Overall\n",
    "There doesn't seem to be a lot of correlation between various SMART attributes, and this varies greatly over different models of hard drive. A decision tree model (random forest) that looks at more than one attribute in order to make a better guess at detecting any future failures. \n"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "scrolled" : true,
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "rf_clf = ensemble.RandomForestClassifier(n_jobs=1, max_depth=3)\n",
    "\n",
    "# here's how the random forest object looks\n",
    "rf_clf.fit(train, train_labels)"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# Apply the Classifier we trained to the test data\n",
    "rf_clf.predict(test)"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# generating the predicted values of possible of features for test data using trained rf_clf, generated above\n",
    "preds = rf_clf.predict_proba(test)\n",
    "\n",
    "# check predicted values of the first 10 observations\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# performing quick ROC and log loss functions to see how the the data looks\n",
    "\n",
    "print('ROC Area Under Curve', metrics.roc_auc_score(y_true=test_labels, y_score=preds[:,1]))"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [
    "# performing quick ROC and log loss functions to see how the the data\n",
    "\n",
    "metrics.roc_auc_score(y_true=test_labels, y_score=preds[:,1])"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "Since, above tell us that the area under curve is about 0.75, so that's a good enough"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "### Challenges: \n",
    " 1. Highly critical features like throughput_performance', 'seek_time_performance', 'high_fly_writes and 'command_timeout' have a lot of missing data. This makes the training dataset unreliable.\n",
    " 2. A sound relationship between these uncorrelated metrics/features is needed to better understand things like:\n",
    "    1. How command_timeout affects retry count or, \n",
    "    2. How reallocated sector changes over time as the drive gets old.\n",
    "    3. Different models are manufactured by different companies, and not all manufacturers have all SMART metrics,\n",
    "    among other factors like usage, data-center wear and tear, climatic conditions. This makes it difficult to design a general training that would work across the board.\n",
    "    4. Data is not normalized and there isn't much information on how to normalize them: \n",
    "    is the reallocated sector by bits or bytes?\n",
    "    are all these drives magnetic tapes, hybrid or SSDs?\n",
    "\n",
    "Normalization would make a much a better regression design, or at least present one such option to do so.\n",
    "\n",
    "\n",
    "#### Our model accurately predicted about 77% of the time that a drive is likely to fail."
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "## Business wide High Level Result\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "SMART systems widely used industry practice around data center management and disk heavy resources. \n",
    "\n",
    "The above case study attempted to analyze and predict future hard drive failures based on the data that was provided. was to predict hard drive failures using available dataset. \n",
    "\n",
    "We identified a few key metrics such as 'throughput_performance', 'reallocated sectors', age of the hard drive using 'power on hours' and a few more. We analyzed their effect over time as the failure rate goes down. \n",
    "\n",
    "There was also some extensive researching done leading up to identifying other highly critical metrics but there seems to be missing data about those metrics. Since there isn't enough detail about the dataset in this case study, some external researching was required to get an understanding.\n",
    "\n",
    "Using provided data, we predicted over 77% of possible failure, but this can be improved further. \n",
    "\n",
    "----------\n",
    "\n",
    "#### Some recommended actions and improvements:\n",
    "1.\tRealistically, since not all Hard Drives are manufactured and used under the same roof it’s a good idea that for future predictions, we use the critical attributes, mentioned above to analyze their effect on per hard drive model instead of a general prediction.\n",
    "2.\tIncluding more data source: \n",
    "a.\tUsing more than one source of information such as operating temperature, throughput, of reads and writes etc. can help build a more robust collection of data that can predict future.\n",
    "3.\tBacking up drives that are showing critical changes.\n"
   ]
  },
  {
   "cell_type" : "markdown",
   "metadata" : { },
   "source" : [
    "## Thanks!\n",
    "\n",
    "Harsh"
   ]
  },
  {
   "cell_type" : "code",
   "execution_count" : null,
   "metadata" : {
    "pycharm" : {
     "is_executing" : false
    }
   },
   "outputs" : [ ],
   "source" : [ ]
  }
 ],
 "metadata" : {
  "kernelspec" : {
   "display_name" : "Python 3",
   "language" : "python",
   "name" : "python3"
  },
  "language_info" : {
   "codemirror_mode" : {
    "name" : "ipython",
    "version" : 3
   },
   "file_extension" : ".py",
   "mimetype" : "text/x-python",
   "name" : "python",
   "nbconvert_exporter" : "python",
   "pygments_lexer" : "ipython3",
   "version" : "3.6.5"
  },
  "pycharm" : {
   "stem_cell" : {
    "cell_type" : "raw",
    "source" : [ ],
    "metadata" : {
     "collapsed" : false
    }
   }
  }
 },
 "nbformat" : 4,
 "nbformat_minor" : 2
}